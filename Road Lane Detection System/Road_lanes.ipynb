{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "def detect_lanes(frame):\n",
        "    # Convert frame to grayscale\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "    # Define region of interest\n",
        "    height, width = frame.shape[:2]\n",
        "    vertices = np.array([[(0, height), (width/2, height/2), (width, height)]], dtype=np.int32)\n",
        "    roi = region_of_interest(edges, vertices)\n",
        "\n",
        "    # Detect lines using Hough Transform\n",
        "    lines = cv2.HoughLinesP(roi, 2, np.pi/180, 100, minLineLength=40, maxLineGap=5)\n",
        "\n",
        "    # Draw lines on the frame\n",
        "    line_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "    if lines is not None:\n",
        "        draw_lines(line_img, lines)\n",
        "\n",
        "    # Overlay lines on the original frame\n",
        "    result = cv2.addWeighted(frame, 0.8, line_img, 1, 0)\n",
        "\n",
        "    return result\n",
        "\n",
        "def region_of_interest(img, vertices):\n",
        "    mask = np.zeros_like(img)\n",
        "    cv2.fillPoly(mask, vertices, 255)\n",
        "    masked_img = cv2.bitwise_and(img, mask)\n",
        "    return masked_img\n",
        "\n",
        "def draw_lines(img, lines, color=[255, 0, 0], thickness=3):\n",
        "    for line in lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "# Read video file\n",
        "cap = cv2.VideoCapture('/content/sample_data/test_video.mp4')\n",
        "\n",
        "# Get video details\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define code and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output_video.mp4', fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Process frame for lane detection\n",
        "    result_frame = detect_lanes(frame)\n",
        "\n",
        "    # Write the resulting frame to the output video file\n",
        "    out.write(result_frame)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2_imshow(result_frame)\n",
        "\n",
        "    # Break the loop when 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release video capture and writer, and close all windows\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "F2wQtay69mBF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}